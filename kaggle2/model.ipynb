{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e6a8cc",
   "metadata": {},
   "source": [
    "# Binary Classification with a Bank Dataset - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e26c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/numpy/_core/getlimits.py:552: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n",
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727dfe6",
   "metadata": {},
   "source": [
    "## Reading from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a76098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "0    0.879558\n",
      "1    0.120442\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./playground-series-s5e8/train.csv')\n",
    "other_data = pd.read_csv('./playground-series-s5e8/bank-full.csv')\n",
    "X_test = pd.read_csv('./playground-series-s5e8/test.csv')\n",
    "data = pd.concat([data, other_data])\n",
    "data = data.drop(columns=[\"id\"])\n",
    "X_test = X_test.drop(columns=[\"id\"])\n",
    "\n",
    "y = data['y']\n",
    "features = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
    "cat_features = ['job', 'marital', 'education', 'default', 'housing','loan','contact','month','poutcome']\n",
    "X = data[features]\n",
    "\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be2b52",
   "metadata": {},
   "source": [
    "## Optuna - Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2255c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_catb(trial):\n",
    "    params = {\n",
    "        'random_state': 42,\n",
    "        'iterations': trial.suggest_int('iterations', 2000, 5000),  # number of trees\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 8),  # tree depth\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10, log=True),  # L2 regularization\n",
    "        'random_strength': trial.suggest_float('random_strength', 0.0, 10.0),  # randomness in splits\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),  # number of splits for numeric features\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),  # feature sampling\n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS']),\n",
    "        'rsm': trial.suggest_float('rsm', 0.5, 1.0)\n",
    "\n",
    "    }\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        scale_pos_weight = len(y_train) / (2 * sum(y_train))\n",
    "\n",
    "        model = CatBoostClassifier(**params, eval_metric='AUC', loss_function='Logloss', verbose=0, class_weights=[1, scale_pos_weight])\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=100)\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, preds)\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(f\"~~~~~~~~Trial {trial.number} mean AUC: {mean_auc:.4f}\\n~~~~~~\")\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d860b7",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7a7384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC: 0.9666\n",
      "Fold 2 AUC: 0.9660\n",
      "Fold 3 AUC: 0.9649\n",
      "Fold 4 AUC: 0.9651\n",
      "Fold 5 AUC: 0.9650\n",
      "Fold 6 AUC: 0.9649\n",
      "Fold 7 AUC: 0.9658\n",
      "Fold 8 AUC: 0.9658\n",
      "Fold 9 AUC: 0.9665\n",
      "Fold 10 AUC: 0.9652\n",
      "Average AUC across folds: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9656"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {'iterations': 2312, 'learning_rate': 0.06641334484629591, 'depth': 11, 'l2_leaf_reg': 4.258468780350662, 'random_strength': 8.767951892289316, 'border_count': 160, 'grow_policy': 'Lossguide', 'colsample_bylevel': 0.5842739001189716, 'bootstrap_type': 'MVS'}\n",
    "\n",
    "auc_scores = []\n",
    "oof_preds_catb = np.zeros(len(X))\n",
    "test_preds_catb = np.zeros(len(X_test))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10 , shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    scale_pos_weight = len(y_train) / (2 * sum(y_train))\n",
    "    \n",
    "    model = CatBoostClassifier(**best_params, eval_metric='AUC', loss_function='Logloss', verbose=0, class_weights=[1, scale_pos_weight])\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=100,cat_features=cat_features)\n",
    "\n",
    "    val_preds = model.predict_proba(X_val)[:, 1] \n",
    "    oof_preds_catb[val_index] = val_preds\n",
    "    \n",
    "    auc = roc_auc_score(y_val, val_preds)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "\n",
    "    test_preds_catb += model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_preds_catb /= kf.n_splits\n",
    "\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "print(f\"Average AUC across folds: {np.mean(auc_scores):.4f}\")\n",
    "# study.optimize(objective_catb, n_trials=10)\n",
    "\n",
    "# # Show best result\n",
    "# print(\"Best AUC:\", study.best_value)\n",
    "# print(\"Best parameters:\", study.best_params)\n",
    "0.9656"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53f02c",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50725b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_340/3381667503.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.education = X.education.map({'primary': 0, 'secondary': 1, 'tertiary': 2})\n",
      "/tmp/ipykernel_340/3381667503.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.default = X.default.map({'no': 0, 'yes': 1})\n",
      "/tmp/ipykernel_340/3381667503.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.housing = X.housing.map({'no': 0, 'yes': 1})\n",
      "/tmp/ipykernel_340/3381667503.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.loan = X.loan.map({'no': 0, 'yes': 1})\n",
      "/tmp/ipykernel_340/3381667503.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.contact = X.contact.map({'cellular': 0, 'telephone': 1})\n",
      "/tmp/ipykernel_340/3381667503.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.month = X.month.map({'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12})\n"
     ]
    }
   ],
   "source": [
    "X.education = X.education.map({'primary': 0, 'secondary': 1, 'tertiary': 2})\n",
    "X_test.education = X_test.education.map({'primary': 0, 'secondary': 1, 'tertiary': 2})\n",
    "\n",
    "X.default = X.default.map({'no': 0, 'yes': 1})\n",
    "X_test.default = X_test.default.map({'no': 0, 'yes': 1})\n",
    "\n",
    "X.housing = X.housing.map({'no': 0, 'yes': 1})\n",
    "X_test.housing = X_test.housing.map({'no': 0, 'yes': 1})\n",
    "\n",
    "X.loan = X.loan.map({'no': 0, 'yes': 1})\n",
    "X_test.loan = X_test.loan.map({'no': 0, 'yes': 1})\n",
    "\n",
    "X.contact = X.contact.map({'cellular': 0, 'telephone': 1})\n",
    "X_test.contact = X_test.contact.map({'cellular': 0, 'telephone': 1})\n",
    "\n",
    "X.month = X.month.map({'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12})\n",
    "X['day_of_year'] = (X['month'] - 1) * 31 + X['day']\n",
    "X['day_sin'] = np.sin(2 * np.pi * X.day_of_year / 372)\n",
    "X['day_cos'] = np.cos(2 * np.pi * X.day_of_year / 372)\n",
    "X['month_sin'] = np.sin(2 * np.pi * X.month / 12)\n",
    "X['month_cos'] = np.cos(2 * np.pi * X.month / 12)\n",
    "\n",
    "X_test.month = X_test.month.map({'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12})\n",
    "X_test['day_of_year'] = (X_test['month'] - 1) * 31 + X_test['day']\n",
    "X_test['day_sin'] = np.sin(2 * np.pi * X_test.day_of_year / 372)\n",
    "X_test['day_cos'] = np.cos(2 * np.pi * X_test.day_of_year / 372)\n",
    "X_test['month_sin'] = np.sin(2 * np.pi * X_test.month / 12)\n",
    "X_test['month_cos'] = np.cos(2 * np.pi * X_test.month / 12)\n",
    "\n",
    "X.poutcome = X.poutcome.map({'failure': -1, 'other': 0, 'success': 1})\n",
    "X_test.poutcome = X_test.poutcome.map({'failure': -1, 'other': 0, 'success': 1})\n",
    "\n",
    "X = X.drop(['day', 'month', 'day_of_year'], axis=1)\n",
    "X_test = X_test.drop(['day', 'month', 'day_of_year'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b484d138",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "885ebfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39785b66",
   "metadata": {},
   "source": [
    "## Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e4546dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.replace('unknown', np.nan)\n",
    "X_test = X_test.replace('unknown', np.nan)\n",
    "\n",
    "X_columns = X.columns\n",
    "X_index = X.index\n",
    "X_test_columns = X_test.columns\n",
    "X_test_index = X_test.index\n",
    "\n",
    "#Imputing missing values\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X_columns, index=X_index)\n",
    "X_test = pd.DataFrame(imputer.fit_transform(X_test), columns=X_test_columns, index=X_test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601b49d",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbc88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age            int64\n",
      "education    float64\n",
      "default        int64\n",
      "balance        int64\n",
      "housing        int64\n",
      "loan           int64\n",
      "contact      float64\n",
      "duration       int64\n",
      "campaign       int64\n",
      "pdays          int64\n",
      "previous       int64\n",
      "poutcome     float64\n",
      "day_sin      float64\n",
      "day_cos      float64\n",
      "month_sin    float64\n",
      "month_cos    float64\n",
      "0            float64\n",
      "1            float64\n",
      "2            float64\n",
      "3            float64\n",
      "4            float64\n",
      "5            float64\n",
      "6            float64\n",
      "7            float64\n",
      "8            float64\n",
      "9            float64\n",
      "10           float64\n",
      "11           float64\n",
      "12           float64\n",
      "13           float64\n",
      "dtype: object\n",
      "age            int64\n",
      "education    float64\n",
      "default        int64\n",
      "balance        int64\n",
      "housing        int64\n",
      "loan           int64\n",
      "contact      float64\n",
      "duration       int64\n",
      "campaign       int64\n",
      "pdays          int64\n",
      "previous       int64\n",
      "poutcome     float64\n",
      "day_sin      float64\n",
      "day_cos      float64\n",
      "month_sin    float64\n",
      "month_cos    float64\n",
      "0            float64\n",
      "1            float64\n",
      "2            float64\n",
      "3            float64\n",
      "4            float64\n",
      "5            float64\n",
      "6            float64\n",
      "7            float64\n",
      "8            float64\n",
      "9            float64\n",
      "10           float64\n",
      "11           float64\n",
      "12           float64\n",
      "13           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Converting categorical columns to string\n",
    "object_cols = ['job', 'marital']\n",
    "X[object_cols] = X[object_cols].astype(str)\n",
    "X_test[object_cols] = X_test[object_cols].astype(str)\n",
    "\n",
    "#One-hot encoding\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(X[object_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.fit_transform(X_test[object_cols]))\n",
    "\n",
    "#Matching indexes\n",
    "OH_cols.index = X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "\n",
    "#Droping original object columns and concatenating\n",
    "num_X = X.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "X = pd.concat([num_X, OH_cols], axis=1)\n",
    "X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "#Changing dtype of columns\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col])\n",
    "    X_test[col] = pd.to_numeric(X_test[col])\n",
    "\n",
    "print(X.dtypes)\n",
    "print(X_test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b7ef3",
   "metadata": {},
   "source": [
    "## Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b0660",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concat() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m age_ed_product = X[\u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m]*X[\u001b[33m'\u001b[39m\u001b[33meducation\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mage_ed_product\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: concat() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "age_ed_product = X['age']*X['education']\n",
    "X = pd.concat([X, age_ed_product], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421bb0c",
   "metadata": {},
   "source": [
    "## Saving new training data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4743530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7e09d",
   "metadata": {},
   "source": [
    "## Optuna - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0f707d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'eval_metric': 'auc',\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-3, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 6.5, 8),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    print(f\"Trial {trial.number} parameters: {params}\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        scale_pos_weight = len(y_train) / (2 * sum(y_train))\n",
    "\n",
    "        model = XGBClassifier(**params, use_label_encoder=False, verbosity=0, class_weights=[1, scale_pos_weight])\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, preds)\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(f\"Trial {trial.number} mean AUC: {mean_auc:.4f}\\n\")\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056fd3e",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f28c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:50:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:51:19] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 AUC: 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:51:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 AUC: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:52:01] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 AUC: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:52:24] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 AUC: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:52:47] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 AUC: 0.9639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:53:08] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 AUC: 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:53:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 AUC: 0.9653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:53:50] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 AUC: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anka335/projects/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [10:54:10] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"class_weights\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 AUC: 0.9643\n",
      "Average AUC across folds: 0.9649\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'lambda': 4.789789675776273, \n",
    "    'alpha': 0.08471537263019147, \n",
    "    'gamma': 5.823912998954795, \n",
    "    'colsample_bytree': 0.6462228625505225, \n",
    "    'subsample': 0.6209806695110034, \n",
    "    'learning_rate': 0.08080462403564155, \n",
    "    'n_estimators': 898, \n",
    "    'max_depth': 12, \n",
    "    'min_child_weight': 6, \n",
    "    'scale_pos_weight': 7.3\n",
    "}\n",
    "\n",
    "auc_scores = []\n",
    "oof_preds_xgb = np.zeros(len(X))\n",
    "test_preds_xgb = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    scale_pos_weight = len(y_train) / (2 * sum(y_train))\n",
    "\n",
    "    model = XGBClassifier(**best_params, class_weights=[1, scale_pos_weight])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    val_preds = model.predict_proba(X_val)[:, 1] \n",
    "    oof_preds_xgb[val_index] = val_preds\n",
    "    \n",
    "    auc = roc_auc_score(y_val, val_preds)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "\n",
    "    test_preds_xgb += model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_preds_xgb /= kf.n_splits\n",
    "\n",
    "print(f\"Average AUC across folds: {np.mean(auc_scores):.4f}\")\n",
    "#study = optuna.create_study(direction='maximize')\n",
    "#study.optimize(objective_xgb, n_trials=30)\n",
    "\n",
    "# Show best result\n",
    "#print(\"Best AUC:\", study.best_value)\n",
    "#print(\"Best parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3047b4",
   "metadata": {},
   "source": [
    "## Optuna - LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2742d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'metric': 'auc',\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 2000,\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 20, 255),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "        'cat_smooth' : trial.suggest_int('min_data_per_groups', 1, 100)\n",
    "    }\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        scale_pos_weight = len(y_train) / (2 * sum(y_train))\n",
    "\n",
    "        model = LGBMClassifier(**params, early_stopping_round=100, verbosity=-1, class_weights=[1, scale_pos_weight])\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"auc\")\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, preds)\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(f\"~~~~~~~~Trial {trial.number} mean AUC: {mean_auc:.4f}\\n~~~~~~\")\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92ebef1",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c944242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC: 0.9672\n",
      "Fold 2 AUC: 0.9668\n",
      "Fold 3 AUC: 0.9662\n",
      "Fold 4 AUC: 0.9663\n",
      "Fold 5 AUC: 0.9659\n",
      "Fold 6 AUC: 0.9654\n",
      "Fold 7 AUC: 0.9666\n",
      "Fold 8 AUC: 0.9671\n",
      "Fold 9 AUC: 0.9670\n",
      "Fold 10 AUC: 0.9654\n",
      "Average AUC across folds: 0.9664\n"
     ]
    }
   ],
   "source": [
    "best_params = {'metric': 'auc', 'random_state': 42, 'n_estimators': 2000,'reg_alpha': 1.167185634134842, 'reg_lambda': 8.79073465010749, 'colsample_bytree': 0.5005629861380371, 'subsample': 0.6822575660406408, 'learning_rate': 0.06493690919467418, 'max_depth': 11, 'num_leaves': 188, 'min_child_samples': 88, 'min_data_per_groups': 1}\n",
    "\n",
    "\n",
    "auc_scores = []\n",
    "oof_preds_lgbm = np.zeros(len(X))\n",
    "test_preds_lgbm = np.zeros(len(X_test))\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    scale_pos_weight = len(y_train) / (2 * sum(y_train))\n",
    "    \n",
    "    model = LGBMClassifier(**best_params, early_stopping_round=100, verbosity=-1, class_weights=[1, scale_pos_weight])\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric=\"auc\")\n",
    "\n",
    "    val_preds = model.predict_proba(X_val)[:, 1] \n",
    "    oof_preds_lgbm[val_index] = val_preds\n",
    "    \n",
    "    auc = roc_auc_score(y_val, val_preds)\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"Fold {fold + 1} AUC: {auc:.4f}\")\n",
    "\n",
    "    test_preds_lgbm += model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_preds_lgbm /= kf.n_splits\n",
    "\n",
    "print(f\"Average AUC across folds: {np.mean(auc_scores):.4f}\")\n",
    "#study = optuna.create_study(direction='maximize')\n",
    "#study.optimize(objective_lgbm, n_trials=30)\n",
    "\n",
    "# Show best result\n",
    "#print(\"Best AUC:\", study.best_value)\n",
    "#print(\"Best parameters:\", study.best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76357d",
   "metadata": {},
   "source": [
    "## Ensembling - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fef2d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_test_preds = pd.DataFrame()\n",
    "#all_test_preds[\"xgboost\"] = test_preds_xgb\n",
    "#all_test_preds[\"lgbm\"] = test_preds_lgbm\n",
    "#all_train_preds = pd.DataFrame()\n",
    "#all_train_preds[\"xgboost\"] = oof_preds_xgb\n",
    "#all_train_preds[\"lgbm\"] = oof_preds_lgbm\n",
    "#all_train_preds[\"y\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc9170b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.column_stack((oof_preds_xgb,oof_preds_lgbm,oof_preds_catb)) #train predictions of xgboost and lightgbm\n",
    "test_stack = np.column_stack((test_preds_xgb,test_preds_lgbm,test_preds_catb)) #test predictions of xgboost and lightgbm\n",
    "\n",
    "final_model = LogisticRegression()\n",
    "\n",
    "final_model.fit(train_stack, y)\n",
    "\n",
    "final_predictions = final_model.predict_proba(test_stack)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366f5dc2",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40e2e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750000    0.007479\n",
      "750001    0.032272\n",
      "750002    0.006847\n",
      "750003    0.006827\n",
      "750004    0.009461\n",
      "            ...   \n",
      "999995    0.006840\n",
      "999996    0.025673\n",
      "999997    0.717756\n",
      "999998    0.006975\n",
      "999999    0.033641\n",
      "Length: 250000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_predictions = pd.Series(final_predictions)\n",
    "final_predictions.index = range(750000, 750000 + len(final_predictions))\n",
    "\n",
    "print(final_predictions)\n",
    "final_predictions.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
